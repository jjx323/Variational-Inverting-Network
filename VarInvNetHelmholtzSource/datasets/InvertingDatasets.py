#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Power by Zongsheng Yue 2019-09-02 15:51:11

import torch
# import h5py as h5
import random
import sys
import cv2
import os
import numpy as np
import torch.utils.data as uData
from skimage import img_as_float32 as img_as_float
from .data_tools import sigma_estimate, random_augmentation_flip_up_down, \
                        random_augmentation, gaussian_kernel
from . import BaseDataSetH5, BaseDataSetImg


# Simulation Datasets:
class SimulateTrain(uData.Dataset):
    def __init__(self, training_data_list, length, radius=5, noise_type='NIIDGauss',
                       noise_estimate=True, chn=1, resize_data=False, index=None, \
                       repeat_number=1):
        super(SimulateTrain, self).__init__()
        # self.u_list = u_list
        # self.d_list = d_list
        # self.dr_list = dr_list
        self.training_data_list = training_data_list
        self.length = length
        self.num_u = len(self.training_data_list)
        self.win = 2*radius + 1
        self.sigma_spatial = radius
        self.noise_estimate = noise_estimate
        self.sigma_min = 0
        self.sigma_max = 20
        self.noise_type = noise_type
        self.chn = chn
        self.resize_data = resize_data
        self.index = index
        self.repeat_number = repeat_number
    
    def __len__(self):
        return self.length

    def generate_sigma_image(self, pch_size):
        if self.noise_type.lower() == 'niidgauss':
            center = [random.uniform(0, pch_size), random.uniform(0, pch_size)]
            scale = random.uniform(pch_size/4, pch_size/4*3)
            kernel = gaussian_kernel(pch_size, pch_size, center, scale)
            up = random.uniform(self.sigma_min/255.0, self.sigma_max/255.0)
            down = random.uniform(self.sigma_min/255.0, self.sigma_max/255.0)
            if up < down:
                up, down = down, up
            up += 5/255.0
            sigma_map = down + (kernel-kernel.min())/(kernel.max()-kernel.min())  *(up-down)
        elif self.noise_type.lower() == 'iidgauss':
            sigma = random.uniform(self.sigma_min, self.sigma_max)
            sigma_map = np.ones((pch_size, pch_size),dtype=np.float32) * (sigma/255.0)
        sigma_map = sigma_map.astype(np.float32)

        return sigma_map[:, :, np.newaxis]
    
    def generate_sigma(self, ll, rr, max_val_data):
        if self.noise_type.lower() == 'iidgauss':
            sigma = random.uniform(self.sigma_min, self.sigma_max)
            sigma_map = (sigma/255.0)*np.repeat(max_val_data.reshape(ll, 1), rr, axis=1) 
        
        sigma_map = sigma_map.astype(np.float32)
        return sigma_map           

    def __getitem__(self, index):
        ind_u = random.randint(0, self.num_u-1)
        # print(self.training_data_list[ind_u])
        training_data = np.load(self.training_data_list[ind_u], allow_pickle=True)
        u, d_accurate, d_clean = training_data[0], training_data[1], training_data[2]
        lu, ru = u.shape
       
        # ## d_list is the data generated by accurate forward solver
        # ## toward the rough forward solver d_list is the noisy data
        # d_accurate = np.load(self.training_data_list[ind_u][1])
        # ## dr_list is the data generated by rough forward solver.
        # ## toward the rough forward solver dr_list is the clean data
        # d_clean = np.load(self.training_data_list[ind_u][2])
      
        if type(self.index) != type(None):
            d_clean = d_clean[self.index, :]
            d_accurate = d_accurate[self.index, :]
        
        ll, rr = d_clean.shape
        sigma_map = self.generate_sigma(ll, rr, np.max(np.abs(d_clean), axis=1))
        
        noise = torch.randn(d_clean.shape).numpy()*sigma_map
        d_noise = d_accurate + noise.astype(np.float32)
        
        d_clean = np.repeat(d_clean, self.repeat_number, axis=0)
        d_noise = np.repeat(d_noise, self.repeat_number, axis=0)
        
        # u, d_noise, d_clean, sigma_map = \
        #        random_augmentation_flip_up_down(u, d_noise, d_clean, sigma_map)
        # u, d_noise, d_clean, sigma_map = random_augmentation(u, d_noise, d_clean, sigma_map)
        
        if self.resize_data == True:
            d_noise = cv2.resize(d_noise, (lu, ru), interpolation=cv2.INTER_AREA)
            d_clean = cv2.resize(d_clean, (lu, ru), interpolation=cv2.INTER_AREA)
        
        if self.noise_estimate: 
            sigma2_map_est = sigma_estimate(d_noise, d_clean, self.win, self.sigma_spatial)[:,:,0]
            sigma2_map_est = torch.from_numpy(sigma2_map_est)
            if self.resize_data == True:
                sigma2_map_gt = cv2.resize(np.square(sigma_map), (lu, ru), interpolation=cv2.INTER_AREA)
            else:
                sigma2_map_gt = np.square(sigma_map)
            sigma2_map_gt = np.where(sigma2_map_gt<1e-10, 1e-10, sigma2_map_gt)
            sigma2_map_gt = torch.from_numpy(sigma2_map_gt)
            
        u = u[np.newaxis, :]
        d_noise = d_noise[np.newaxis, :]
        d_clean = d_clean[np.newaxis, :]
        sigma2_map_gt = sigma2_map_gt[np.newaxis, :]
        sigma2_map_est = sigma2_map_est[np.newaxis, :]
        
        u = torch.tensor(u, dtype=sigma2_map_gt.dtype)
        d_noise = torch.tensor(d_noise, dtype=sigma2_map_gt.dtype)
        
        if self.noise_estimate:
            return d_noise, d_clean, u, sigma2_map_est, sigma2_map_gt
        else:
            return d_noise, d_clean, u
        

class SimulateTest(uData.Dataset):
    def __init__(self, im_list, h5_path, chn=3):
        super(SimulateTest, self).__init__()
        self.im_list = im_list
        self.h5_path = h5_path
        self.chn = chn

    def __len__(self):
        return len(self.im_list)

    def __getitem__(self, index):
        im_gt = cv2.imread(self.im_list[index], 1)
        if self.chn == 3:
            im_gt = im_gt[:, :, ::-1]
        elif self.chn == 1:
            im_gt = cv2.cvtColor(im_gt, cv2.COLOR_BGR2GRAY)
            im_gt = im_gt[:, :, np.newaxis]
        im_key = os.path.basename(self.im_list[index]).split('.')[0]

        with h5.File(self.h5_path, 'r') as h5_file:
            noise = np.array(h5_file[im_key][:,:,:self.chn])
        H, W, _ = noise.shape
        im_gt = img_as_float(im_gt[:H, :W])
        im_noisy = im_gt + noise

        im_gt = torch.from_numpy(im_gt.transpose((2, 0, 1))).type(torch.float32)
        im_noisy = torch.from_numpy(im_noisy.transpose((2, 0, 1))).type(torch.float32)

        return im_noisy, im_gt

